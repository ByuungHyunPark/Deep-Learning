{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 링크\n",
    "- https://koreanfoodie.me/157\n",
    "- https://nbviewer.jupyter.org/github/SDRLurker/deep-learning/blob/master/5%E1%84%8C%E1%85%A1%E1%86%BC.ipynb\n",
    "- 밑바닥부터 시작하는 딥러닝1 책"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Affine/Softmax 계층 구현하기\n",
    "##### 5.6.1 Affine 계층\n",
    "신경망의 순전파에서는 가중치 신호의 총합을 계산하기 위해 행렬의 내적__(np.dot())__을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(2, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.rand(2) # 입력\n",
    "W = np.random.rand(2, 3) #가중치\n",
    "B = np.random.rand(3)   #편향\n",
    "\n",
    "print(X.shape) #(2, )\n",
    "print(W.shape) #(2, 3)\n",
    "print(B.shape) #(3, )\n",
    "\n",
    "Y = np.dot(X, W) + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__위 코드를 계산 그래프를 나타내면 다음과 같다.__\n",
    "![](img/affine1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $X$와 $W$의 내적은 대응하는 차원의 원소 수를 일치 시켜야 함<br><br>\n",
    "__어파인 변환(Affine Transformation) :__ 신경망의 순전파 때 수행하는 행렬의 내적. 기하학 용어<br><br>\n",
    "이 계산 그래프는 __행렬__이 흐름\n",
    "\n",
    "<u>__식 5.13 행렬을 사용한 역전파 전개식__</u> : __가장 핵심이라 생각함__\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial X} = \\frac{\\partial L}{\\partial Y}W^T\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W} = X^T\\frac{\\partial L}{\\partial Y}\n",
    "$$\n",
    "\n",
    "$W^T$는 행렬$W$의 전치행렬을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.6.2 배치용 aFFINE 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지의 Affine 계층은 입력데이터로 $X$ 하나만을 고려한 것이었다. <br>\n",
    "이번 절에서는 __데이터 N개를 묶어 순전파__ 하는 경우, 즉 배치용(데이터 묶음) Affine 계층을 생각해 보자.\n",
    "![](img/affine3.png)\n",
    "\n",
    "<u>__기존과 다른 부분은 입력인 $X$의 형상이 (N,2)가 된 것 뿐이다.__</u> <br>\n",
    "그 뒤로는 지금까지와 같이 계산 그래프의 순서를 따라 순순히 행렬 계산을 하게 된다.\n",
    "\n",
    "\n",
    "예를 들어 N=2(데이터가 2개)로 한 경우, 편향은 그 두 데이터 각각에 더해집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0],\n",
       "       [10, 10, 10]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dot_W = np.array([[0, 0, 0], [10, 10, 10]])\n",
    "B = np.array([1, 2, 3])\n",
    "\n",
    "X_dot_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [11, 12, 13]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dot_W + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순전파의 편향 덧셈은 각각의 데이터(1번째 데이터, 2번째 데이터)에 더해짐<br><br>\n",
    "\n",
    "역전파 때는 각 데이터의 역전파 값이 편향의 원소에 모여야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dY = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "dY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dB = np.sum(dY, axis=0)\n",
    "dB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Affine 구현\n",
    "\n",
    "common/layer.py 파일의 Affine 구현은 입력 데이터가 텐서(4차원 데이터)인 경우도 고려. 다음 구현과 약간 차이가 있다. \n",
    "\n",
    "![](img/affine4.png)\n",
    "__Affine 코드 이해를 위한 그림__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis = 0)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Softmax-with-Loss 계층\n",
    "\n",
    "__1) 신경망은 추론과 학습으로 구성__\n",
    "- 1. 추론 : 가장 좋은 결과 찾기(softmax함수와 같은 활성하ㅗ 함수를 사용하지 않고 점수 그대로 사용)\n",
    "- 2. 학습 : 변수를 수정해서 추론에서 높은 값을 확률 1에 가깝게 만들고, 낮은 값은 확률 0이 되게 함\n",
    "    - 이 중, 학습에 필요한 것이 Softmax함수이다.\n",
    "\n",
    "__2) Softmax 함수는 입력값을 확률 형태로 normalize하여 결과값 출력 (출력값을 이용하여 모델 업데이트)__\n",
    "\n",
    "\n",
    "- 정답지(Label)이 있어야 학습이 되어 차이값을 앞 W,B값에 반영\n",
    "    - ex) 들어온 추론에서는 3이 가장 높은 값이었고 확률이 0.991이었다면, W, B를 조절해서 확률을 1에 가깝게 함\n",
    "    - => Softmax 결과를 손실함수로 오차 계산 (by Cross Entropy Error)\n",
    "    - 활성화함수는 Mean Squared Error를 통해 오차 계산\n",
    "    \n",
    "__3) Softmax__\n",
    "- __결과에 대한 값의 합이 1이 되도록 정규화시켜주는 역할도 함__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01821127 0.24519181 0.73659691]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def softmax(a) :\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y\n",
    "\n",
    "a = np.array([0.3, 2.9, 4.0])\n",
    "\n",
    "print(softmax(a))              # softmax 결과값 출력\n",
    "print(sum(softmax(a)))         # 결과값은 합은 1이 됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/WegraLee/deep-learning-from-scratch/blob/master/common/functions.py 소스 참고\n",
    "# 3.5.2 소프트맥스 함수 구현시 주의점 참고\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# 4.2.2. 교차 엔트로피 오차 참고\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실\n",
    "        self.y = None    # softmax의 출력\n",
    "        self.t = None    # 정답 레이블(원-핫 벡터)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__※ 주의점 :  역전파 때는 전파하는 값을 배치의 수(batch_size)로 나눠, 데이터 1개당 오차를 앞 계층으로 전파함__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
