{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER5 순환신경망(RNN)\n",
    "##### 피드포워드(feed forward) 신경망\n",
    "- 흐름이 단방향\n",
    "- 시계열 데이터의 성질(패턴)을 충분히 학습할 수 없음\n",
    "\n",
    "__순환 신경망(Recurrent Neural Network, RNN)의 등장__\n",
    "\n",
    "## 5.1 확률과 언어 모델\n",
    "##### 5.1.1 word2vec 을 확률 관점에서 바라보다\n",
    "CBOW(Continuous bag-of-words)모델 <br>\n",
    "- CBOW 모델의 학습\n",
    "    - 손실함수(말뭉치 전체의 손실함수의 총합)을 최소화하는 가중치 매개변수를 찾는다\n",
    "- 맥락 안의 단어 순서가 무시된다는 한계가 있다.\n",
    "    - 말뭉치 : $w_1, w_2, w_3, ..., w_t$\n",
    "    \n",
    "> - 맥락을 좌우 대칭으로 생각 <br>\n",
    "> - $t$번째 단어를 __타깃__으로 그 전후 단어($t-1$)번째 단어와 ($t+1$)번째 단어를 __맥락__으로 취급\n",
    "\n",
    "![](img/fig-5-1.png)\n",
    "\n",
    "$w(t-1)$과 $w(t+1)$이 주어졌을 때 타깃이 $w_t$가 될 확률을 수식으로 표현한다면\n",
    "$$\n",
    "P(w_t|w_{t-1}, w_{t+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 맥락을 왼쪽 윈도우만으로 한정\n",
    "![](img/fig-5-1.png)\n",
    "\n",
    "$w_{t-2}$과 $w_{t-1}$이 주어졌을 때 타깃이 $w_t$가 될 확률(CBOW모델이 출력할 확률)을 수식으로 표현하면\n",
    "\n",
    "$$\n",
    "P(w_t|w_{t-2}, w_{t-1})\n",
    "$$\n",
    "\n",
    "CBOW 모델이 다루는 손실 함수\n",
    "\n",
    "$$\n",
    "L = -logP(w_t|w_{t-2}, w_{t-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.2언어 모델(Language Model)\n",
    "단어 나열에 확률을 부여 <br>\n",
    "특정한 단어의 시퀀스에 대해 그 시퀀스가 일어날 가능성이 어느정도인지(얼마나 자연스러운 단어 순서인지)를 확률로 평가한다. <br>\n",
    "- 언어 모델의 사용\n",
    "- 기계 번역과 음성 인식\n",
    "- 새로운 문장을 생성\n",
    "\n",
    "$w_1, ... , w_m$ 이라는 $m$개의 단어로 된 문장이 있을 때 <br>\n",
    "$w_1, ... , w_m$ 순서로 출현할 확률 $P(w_1, ... , w_m)$ <br>\n",
    "(여러 사건이 동시에 일어날 확률이므로 동시확률이라고 한다.)\n",
    "\n",
    "![](img/e-5-4.png) \n",
    "__동시확률은 사후 확률의 총 곱으로 나타낼 수 있다.__ <br>\n",
    "\n",
    "_이 사후 확률은 타깃 단어보다 왼쪽에 있는 단어를 맥락(조건)으로 했을 때의 확률이라는 것에 주목해야 한다._\n",
    "\n",
    "![](img/fig-5-3.png)\n",
    "\n",
    "____확률의 곱셈정리___\n",
    "$$\n",
    "P(A,B) = P(A|B)P(B)\n",
    "$$\n",
    "\n",
    "A, B가 모두 일어날 확률 $P(A,B)$는 $B$가 일어날 확률 P(B)와 B가 일어난 후 A가 일어날 확률 $P(A|B)$를 곱한 값과 같다.\n",
    "\n",
    "![](img/e-5-6.png)\n",
    "![](img/e-5-7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.3 CBOW 모델을 언어 모델로\n",
    "- word2vec의 CBOW 모델을 언어 모델에 적용하려면 맥락의 크기를 특정 값으로 한정하여 근사적으로 나타낼 수 있다.\n",
    "- 맥락의 크기는 임의 길이로 설정할 수 있지만, 결국 특정 길이로 고정된다.\n",
    "    - 예를 들어 __왼쪽 10개의 단어를 맥락으로 CBOW 모델을 만든다고 하면 그 맥락보다 더 왼쪽에 있는 단어의 정보는 무시된다.__\n",
    "- __CBOW모델의 맥락 크기를 키울 수는 있으나, 맥락 안의 단어 순서가 무시된다는 한계가 있다.__\n",
    "- 맥락의 단어 순서를 고려하기 위해 맥락의 단어 벡터를 은닉층에서 연결(concatenate)하는 방식을 생각할 수 있으나, 맥락의 크기에 비례해 가중치 매개변수가 늘어난다는 문제가 발생한다.\n",
    "\n",
    "> 그래서 순환신경망 즉 RNN이 등장하게 되었는데, RNN은 맥락이 아무리 길더라도 맥락의 정보를 기억하는 메커니즘을 갖추고 있기에, 아무리 긴 시계열 데이터에도 대응할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.1 순환하는 신경망\n",
    "순환하기 위해서는 __닫힌 경로__가 필요하다. <br>\n",
    "__닫힌 경로__혹은 __순환하는 경로__가 존재해야 데이터가 같은 장소를 반복해 왕래할 수 있고, 데이터가 순환하면서 과거의 정보를 기억하는 동시에 최신 데이터로 갱신 될 수 있다.\n",
    "![](img/fig-5-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__t : 시각__ <br>\n",
    "시계열 데이터($x_0, x_1, ...x_t, ...)$가 RNN 계층에 입력되고 이에 대응해 $(h_0, h_1, ..., h_t, ...)$가 출력된다. <br>\n",
    "각 시각에 입력되는 $x_t$를 벡터라고 가정했을 때 문장(단어 순서)을 다루는 경우를 예로 든다면 각 단어의 분산 표현(단어 벡터)이 $x_t$가 되며, 이 분산표현이 순서대로 하나씩 RNN계층에 입력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.2 순환구조 펼치기\n",
    "![](img/fig-5-8.png)\n",
    "\n",
    "RNN계층의 순환 구조를 펼침으로써 오른쪽으로 성장하는 긴 신경망으로 변신<br>\n",
    "피드포워드 신경망(데이터가 한 방향으로만 흐른다)과 같은 구조잊미나, 위 그림에서는 다수의 RNN계층 모두가 실제로는 '같은 계층'인 것이 지금까지의 신경망과는 다른 점이다. <br>\n",
    "\n",
    "각 시각의 RNN계층은 그 계층으로의 입력과 1개전의 RNN 계층으로부터의 출력을 받는데, 이 두 정보를 바탕으로 현 시각의 출력을 계산한다. <br>\n",
    "\n",
    "$$\n",
    "h_t = tanh(h_{t-1}W_h + x_tW_x + b)\n",
    "$$\n",
    "\n",
    "\n",
    "- $W_x$ : 입력 $x$를 출력 $h$로 변환하기 위한 가중치\n",
    "- $w_H$ : 1개의 RNN 출력을 다음 시각의 출력으로 변환하기 위한 가중치\n",
    "- $b$ : 편향\n",
    "- $h_{t-1}, x_t$ : 행 벡터\n",
    "\n",
    "$h_t$는 다른 계층을 향해 위쪽으로 출력되는 동시에 다음 시각의 RNN계층(자기 자신)을 향해 오른쪽으로도 출력된다. RNN의 출력 $h_t$는 은닉상태(hidden state) 혹은 은닉 상태 벡터(hidden state vector)라고 한다.\n",
    "\n",
    "> RNN은 $h$라는 '상태'를 가지고 있으며, 위의 식의 형태로 갱신된다고 해석할 수 있다. <br>\n",
    "> RNN계층을 '상태를 가지는 계층' 혹은 '메모리(기억력)가 있는 계층'이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.3 BPTT\n",
    "![](img/fig-5-10.png)\n",
    "\n",
    "순환 구조를 펼친 후의 RNN에는 (일반적인) 오차역전파법을 적용할 수 있다.<br>\n",
    "먼저 순전파를 수행하고 이어서 역전파를 수행하여 원하는 기울기를 구할 수 있다.<br>\n",
    "\n",
    "여기서의 오차역전파법은 '시간 방향으로 펼친 신경망의 오차역전파법' 이란 뜻으로 __BPTT(BackPropagation Through Time)__이라고 한다. <br><br>\n",
    "##### 문제점\n",
    "- 시계열 데이터의 시간 크기가 커지는 것에 비례하여 BPTT가 소비하는 컴퓨팅 자원도 증가\n",
    "- 시간 크기가 커지면 역전파 시의 기울기가 불안정해짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.4 Truncated BPTT\n",
    "__Truncated BPTT__ : 시간축 방향으로 너무 길어진 신경망을 적당한 지점에서 잘라내어 작은 신경망 여러개로 만들어 잘라낸 작은 신경망에서 오차역전파법을 수행한다. <br>\n",
    "- 계층이 너무 길면 계산량과 메모리 사용량 등이 문제가 되고 계층이 길어짐에 따라 신경망을 하나 통과할 때마다 기울기 값이 조금씩 작아져서 이전 시각 $t$까지 역전파되기 전에 0이 되어 소멸할 수 있다.\n",
    "- 순전파의 연결을 그대로 유지하면서(__데이터를 순서대로 입력해야 한다__) 역전파의 연결은 적당한 길이로 잘라내어 잘라낸 신경망 단위로 학습을 수행한다.\n",
    "- 역전파의 연결을 잘라버리면 그보다 미래의 데이터에 대해서는 생각할 필요가 없어지기 때문에 각각의 블록 단위로 미래의 블록과는 독립적으로 오차역전파법을 완결시킨다. \n",
    "    - __블록__ : 역전파가 연결되는 일련의 RNN계층\n",
    "- 순전파를 수행하고 그 다음 역전파를 수행하여 원하는 기울기를 구한다.\n",
    "- 다음 역전파를 수행할 때 앞 블록의 마지막 은닉 상태인 $h_t$가 필요하다.\n",
    "- $h_t$로 순전파가 계속 연결될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.5 Truncated BPTT의 미니배치 학습\n",
    "미니배치 학습을 수행할 때는 각 미니배치의 시작 위치를 __오프셋__으로 옮겨준 후 순서대로 제공하면 된다. 또한 데이터를 순서대로 입력하다가 끝에 도달하면 다시 처음부터 입력하도록 한다.\n",
    "\n",
    "##### 오프셋\n",
    "> 일반적으로 동일 오브젝트 안에서 오브젝트 처음부터 주어진 요소나 지점까지의 변위차를 나타내는 정수형<br>\n",
    "> &nbsp;__예)__ 문자 A의 배열이 abcdef 를 포함한다면 'c'문자는 A시작점에서 2의 오프셋을 지닌다고 할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_미니배치를 두 개로 구성해 학습할 때,_ <br>\n",
    "__첫 번째 미니배치__ 때는 처음부터 순서대로 데이터를 제공 <br>\n",
    "__두 번째 미니배치__ 때는 500번째 데이터를 시작 위치로 정하고, 그 위치부터 다시 순서대로 데이터를 제공\n",
    "![](img/fig-5-15.png)\n",
    "\n",
    "&#x2713; Truncated BPTT의 원리는 단순하지만 데이터 제공 방법 두가지를 주의<br>\n",
    ": 데이터를 순서대로 제공하기, 미니배치별로 데이터를 제공하는 시작 위치를 옮기기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 RNN 구현\n",
    "![](img/fig-5-16.png)\n",
    "\n",
    "- 길이가 $T$인 시계열 데이터를 받는다.\n",
    "- 각 시각의 은닉 상태를 $T$개 출력한다.\n",
    "- 모듈화를 생각해 위의 그림의 신경망을 '하나의 계층'으로 구현한다.\n",
    "\n",
    "![](img/fig-5-17.png)\n",
    "\n",
    "$xs$를 입력하면 $hs$를 출력하는 단일 계층 <br>\n",
    "Time RNN 계층 내에서 한 단계의 작업을 수행하는 계층을 __RNN계층__이라고 하고 <br>\n",
    "$T$개 단계분의 작업을 한꺼번에 처리하는 계층을 __Time RNN계층__이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.1 RNN 계층 구현\n",
    "\n",
    "$$h_t = tanh(h_{t-1}W_h + w_tW_x + b)$$\n",
    "\n",
    "![](img/fig-5-18.png)\n",
    "\n",
    "- $N$ : 미니배치 크기\n",
    "- $D$ : 입력 벡터의 차원 수\n",
    "- $H$ : 은닉 상태 벡터의 차원 수\n",
    "\n",
    "__RNN 처리를 한 단계만 수행하는 RNN 클래스 구현__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN 클래스의 초기화와 순전파 메서드를 구현\n",
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        #가중치 2개, 편향 1개\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        #각 매개변수에 대응하는 형태로 기울기를 초기화한 후 grads에 저장\n",
    "        self.cache = None\n",
    "        #역전파 계산 시 사용하는 중간 데이터를 담은 cache를 None으로 초기화\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        #아래로부터의 입력 x와 왼쪽으로부터의 입력 h_prev\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\n",
    "        #matmul: 행렬의 곱\n",
    "        h_next = np.tanh(t)\n",
    "\n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "    \n",
    "    #RNN 계층의 역전파 메서드 구현\n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "\n",
    "        dt = dh_next*(1 - h_next**2)\n",
    "        db = np.sum(dt, axis = 0)\n",
    "        dWh = np.matmul(h_prev.T, dt)\n",
    "        dh_prev = np.matmul(dt, Wh.T)\n",
    "        dWx = np.matmul(x.T, dt)\n",
    "        dx = np.matmul(dt, Wx.T)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fig-5-20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.2 Time RNN 계층 구현\n",
    "RNN계층 T개를 연결한 신경망 Time RNN 계층 <br>\n",
    "RNN 계층의 은닉 상태 $h$를 인스턴스 변수로 유지해 은닉 상태를 __인계__받는 용도로 이용한다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fig-5-22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 계층의 은닉상태를 Time RNN 계층에서 관리하면 Time RNN사용자는 RNN계층 사이에서 은닉상태를 '인계하는 작업'을 생각하지 않아도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN클래스를 이용해 T개 단계의 처리를 한꺼번에 수행하는 계층을 \n",
    "#TimeRNN이란 이름의 클래스로 완성한다.\n",
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.dh = None, None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h)\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:, t, :] + dh)\n",
    "            dxs[:, t, :] = dx\n",
    "\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 시계열 데이터 처리 계층 구현\n",
    "##### 5.4.1 RNLLM의 전체 그림\n",
    "\n",
    "RNNLM(RNN Language Model) : RNN을 사용한 언어 모델\n",
    "\n",
    "![](img/fig-5-25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Embedding : 단어 ID를 단어의 분산 표현(단어 벡터)으로 변환\n",
    "- RNN계층 : 은닉 상태를 다음 층으로(위쪽으로) 출력함과 동시에 다음 시각의 RNN 계층으로(오른쪽으로) 출력한다.\n",
    "- RNN계층이 위로 출력한 은닉 상태는 Affine계층을 거쳐 softmax계층으로 전해진다.\n",
    "<br><br>\n",
    "RNNLM은 지금까지 입력된 단어를 '기억'하고 그것을 바탕으로 다음에 출현할 단어를 예측한다. <br>\n",
    "RNN계층이 과거에서 현재로 데이터를 계속 흘려보내줌으로써 과거의 정보를 인코딩해 저장(기억)할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4.2 Time계층 구현\n",
    "__※ 시계열 데이터를 한꺼번에 처리하는 계층 <br>__\n",
    "Time Embedding, Time Affine... <br>\n",
    "Time 계층은 간단하게 구현할 수 잇다. <br>\n",
    "예를 들어 Time Affine계층은 Affine계층을 T개 준비해서 각 시각의 데이터를 개별적으로 처리하면 된다. <br>\n",
    "\n",
    "시계열 버전의 Softmax계층을 구현할 때는 손실 오차를 구하는 Cross Entropy Error 게층도 함께 구현한다.\n",
    "![](img/fig-5-29.png)\n",
    "\n",
    "- $x_0, x_1, ...$ : 아래층에서부터 전해지는 점수(확률로 정규화되기 전의 값)\n",
    "- $t_0, t_1, ...$ : 정답 레이블\n",
    "$T$개의 Softmax with Loss 계층이 각각이 손실을 산출하고 그 손실들을 합산해 평균한 값이 최종 손실이 된다.\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{T}(L_0+L_1+ ... + L_{T-1})\n",
    "$$\n",
    "\n",
    "__Time Softmax with Loss__ 계층도 시계열에 대한 평균을 구하는 것으로 데이터 1개당 평균 손실을 구해 최종 출력으로 내보낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLM 학습과 평가\n",
    "##### 5.5.1 RNNLM 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common.time_layers import *\n",
    "\n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fig-5-31.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.5.2 언어 모델의 평가\n",
    "언어 모델은 주어진 주어진 관거 단어(정보)로부터 다음에 출현할 단어의 확률분포를 출력한다. 이때 언어 모델의 예측 성능을 평가하는 척도로 혼란도(perplexity)를 자주 이용한다. <br>&nbsp;\n",
    "\n",
    "- __혼란도(perplexity)__ : 간단히 말하면 '확률의 역수'이다. (데이터 수가 하나일 때에 정확히 일치하며, 작을 수록 좋은 값이다.\n",
    "- __분기수(number of branches)__ : 다음에 취할 수 있는 선택사항의 수(다음에 출현할 수 있는 단어의 후보 수)\n",
    "\n",
    "__ex)__\n",
    "- 분기수가 1.25 => 다음에 출현할 수 있는 단어의 후보를 1개 정도로 좁혔다(좋은 모델)\n",
    "- 분기수가 5 => 후보가 아직 5개(나쁜 모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__입력 데이터가 여러개일 때__\n",
    "$$\n",
    "L = -\\frac{1}{N}\\sum_n\\sum_k t_{nk}logy_{nk}\n",
    "$$\n",
    "$$\n",
    "perplexity = e^L\n",
    "$$\n",
    "\n",
    "$N$ : 데이터의 총 개수 <br>\n",
    "$t_n$ : 원핫 벡터로 나타낸 정답 레이블 <br>\n",
    "$t_{nk}$ : $n$개째 데이터의 $k$번째 값 <br>\n",
    "$y_{nk}$ : 확률분포(신경망에서 sms Softmax의 출력) <br>\n",
    "$L$ : 신경망의 손실, 교차 엔트로피 오차를 뜻하는 식과 같은 식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.5.3 RNNLM의 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 크기: 1000, 어휘 수: 418\n",
      "| 에폭 10 | 퍼플렉서티 192.87\n",
      "| 에폭 20 | 퍼플렉서티 183.45\n",
      "| 에폭 30 | 퍼플렉서티 156.65\n",
      "| 에폭 40 | 퍼플렉서티 124.26\n",
      "| 에폭 50 | 퍼플렉서티 81.69\n",
      "| 에폭 60 | 퍼플렉서티 48.20\n",
      "| 에폭 70 | 퍼플렉서티 28.36\n",
      "| 에폭 80 | 퍼플렉서티 15.26\n",
      "| 에폭 90 | 퍼플렉서티 8.95\n",
      "| 에폭 100 | 퍼플렉서티 5.67\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5     # Truncated BPTT가 한 번에 펼치는 시간 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기(전체 중 1000개만)\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]  # 입력\n",
    "ts = corpus[1:]   # 출력(정답 레이블)\n",
    "data_size = len(xs)\n",
    "print('말뭉치 크기: %d, 어휘 수: %d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 학습 시 사용하는 변수\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "# 미니배치의 각 샘플의 읽기 시작 위치를 계산\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # 미니배치 취득\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "        # 기울기를 구하여 매개변수 갱신\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # 에폭마다 퍼플렉서티 평가\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('| 에폭 %d | 퍼플렉서티 %.2f'\n",
    "              % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n",
    "\n",
    "# 그래프 그리기\n",
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.5.4 RNNLM의 Trainer 클래스\n",
    "\n",
    "RNNLM 학습을 수행하는 RNNlmTrainer 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 418.76\n",
      "| 에폭 2 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 357.47\n",
      "| 에폭 3 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 250.24\n",
      "| 에폭 4 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 218.08\n",
      "| 에폭 5 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 208.94\n",
      "| 에폭 6 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 206.90\n",
      "| 에폭 7 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 199.01\n",
      "| 에폭 8 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 200.37\n",
      "| 에폭 9 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 195.40\n",
      "| 에폭 10 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 191.08\n",
      "| 에폭 11 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 192.28\n",
      "| 에폭 12 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 188.03\n",
      "| 에폭 13 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 191.38\n",
      "| 에폭 14 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 187.10\n",
      "| 에폭 15 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 185.38\n",
      "| 에폭 16 |  반복 1 / 19 | 시간 0[s] | 퍼플렉서티 189.60\n",
      "| 에폭 17 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 187.05\n",
      "| 에폭 18 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 183.77\n",
      "| 에폭 19 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 181.07\n",
      "| 에폭 20 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 180.29\n",
      "| 에폭 21 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 178.03\n",
      "| 에폭 22 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 177.70\n",
      "| 에폭 23 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 178.83\n",
      "| 에폭 24 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 177.72\n",
      "| 에폭 25 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 170.98\n",
      "| 에폭 26 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 172.15\n",
      "| 에폭 27 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 170.49\n",
      "| 에폭 28 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 168.68\n",
      "| 에폭 29 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 162.98\n",
      "| 에폭 30 |  반복 1 / 19 | 시간 1[s] | 퍼플렉서티 159.74\n",
      "| 에폭 31 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 157.01\n",
      "| 에폭 32 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 153.67\n",
      "| 에폭 33 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 150.10\n",
      "| 에폭 34 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 151.06\n",
      "| 에폭 35 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 146.48\n",
      "| 에폭 36 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 141.70\n",
      "| 에폭 37 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 142.62\n",
      "| 에폭 38 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 133.45\n",
      "| 에폭 39 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 128.78\n",
      "| 에폭 40 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 125.95\n",
      "| 에폭 41 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 120.83\n",
      "| 에폭 42 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 119.77\n",
      "| 에폭 43 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 114.84\n",
      "| 에폭 44 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 110.59\n",
      "| 에폭 45 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 102.77\n",
      "| 에폭 46 |  반복 1 / 19 | 시간 2[s] | 퍼플렉서티 101.17\n",
      "| 에폭 47 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 100.52\n",
      "| 에폭 48 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 94.59\n",
      "| 에폭 49 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 90.87\n",
      "| 에폭 50 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 84.84\n",
      "| 에폭 51 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 84.43\n",
      "| 에폭 52 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 76.79\n",
      "| 에폭 53 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 74.80\n",
      "| 에폭 54 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 70.15\n",
      "| 에폭 55 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 70.00\n",
      "| 에폭 56 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 65.85\n",
      "| 에폭 57 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 62.36\n",
      "| 에폭 58 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 57.32\n",
      "| 에폭 59 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 54.80\n",
      "| 에폭 60 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 51.85\n",
      "| 에폭 61 |  반복 1 / 19 | 시간 3[s] | 퍼플렉서티 48.68\n",
      "| 에폭 62 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 46.53\n",
      "| 에폭 63 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 45.08\n",
      "| 에폭 64 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 42.97\n",
      "| 에폭 65 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 38.73\n",
      "| 에폭 66 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 36.22\n",
      "| 에폭 67 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 35.50\n",
      "| 에폭 68 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 33.38\n",
      "| 에폭 69 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 31.15\n",
      "| 에폭 70 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 28.59\n",
      "| 에폭 71 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 27.24\n",
      "| 에폭 72 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 25.89\n",
      "| 에폭 73 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 24.15\n",
      "| 에폭 74 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 22.70\n",
      "| 에폭 75 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 22.09\n",
      "| 에폭 76 |  반복 1 / 19 | 시간 4[s] | 퍼플렉서티 20.85\n",
      "| 에폭 77 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 19.13\n",
      "| 에폭 78 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 18.03\n",
      "| 에폭 79 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 17.44\n",
      "| 에폭 80 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 16.35\n",
      "| 에폭 81 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 14.91\n",
      "| 에폭 82 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 14.43\n",
      "| 에폭 83 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 13.69\n",
      "| 에폭 84 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 13.36\n",
      "| 에폭 85 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 12.22\n",
      "| 에폭 86 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 11.69\n",
      "| 에폭 87 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 11.30\n",
      "| 에폭 88 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 10.40\n",
      "| 에폭 89 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 9.96\n",
      "| 에폭 90 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 9.45\n",
      "| 에폭 91 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 9.17\n",
      "| 에폭 92 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 8.84\n",
      "| 에폭 93 |  반복 1 / 19 | 시간 5[s] | 퍼플렉서티 8.06\n",
      "| 에폭 94 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 7.66\n",
      "| 에폭 95 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 7.34\n",
      "| 에폭 96 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 7.19\n",
      "| 에폭 97 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 7.02\n",
      "| 에폭 98 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 6.69\n",
      "| 에폭 99 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 6.26\n",
      "| 에폭 100 |  반복 1 / 19 | 시간 6[s] | 퍼플렉서티 6.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from dataset import ptb\n",
    "\n",
    "# 하이퍼 파라미터 설정\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 5      # RNN을 펼치는 크기\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000  # 테스트 데이터셋을 작게 설정\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "xs = corpus[:-1]  #입력\n",
    "ts = corpus[1:]   #출력(정답 레이블)\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size) # 학습 수행\n",
    "# 1. 미니배치를 '순차적'으로 만들어\n",
    "# 2. 모델의 순전파와 역전파를 호출하고\n",
    "# 3. 옵티마이저로 가중치를 갱신하고\n",
    "# 4. 퍼플렉시티를 구한다.\n",
    "\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
